---
title: 'An Introduction to LISA and IG-LLM'
date: 2024-05-16
permalink: /posts/2024/05/lisa/
tags:
  - Machine Learning
  - LLM
  - Graphics
---
In this blog post, we introduce LISA: Learning Interpretable Skill Abstractions from Language, which is a hierarchical imitation learning framework that aims to bridge the gap between human language and machine action. LISA is a new approach to enabling machines to understand and execute complex tasks described in natural language. LISA has been tested on navigation and robotic manipulation tasks, and it outperforms a strong non-hierarchical Decision Transformer baseline in low data regimes. 

## Language-conditioned Skill Learning

In the domain of machine learning, intelligent machines are designed to solve complex tasks within their environment and find optimal solutions to unseen scenarios. The interaction between humans and intelligent machines is also a crucial part of the process. In the sequential-decision making setting, when provided expert data, an agent can learn to perform these tasks via multi-task imitation learning (IL). The task specification to an agent may happen through task ID, goal images or goal demonstrations. However, these specifications demand effort and may be hard to manage and supply during testing. Here it is highly desirable that we can specify instructions in natural language, which then the machines can carry out to solve long-horizon tasks. Therefore, the focus lies on multi-task IL setup with task-specification through language.

<!-- ## How Language-conditioned Skill Learning Works -->

The aim of language-conditioned IL is to solve tasks in an environment based on language-conditioned trajectories at training time and a natural language instruction at test time. This can be challenging if the task requires completing multiple sub-tasks sequentially. To make this possible, LISA uses two-level-architecture:  a skill predictor and a policy network. To explain these, let's consider the task instruction "pull the handle and move black mug right". The following graphical representation is taken from the original [paper](https://arxiv.org/abs/2203.00054):
<!-- The skill predictor uses an already learnt vector codebook to predict quantized skills. The policy uses these skill vector codes to predict actions. Let's consider the task instruction "pull the handle and move black mug right". -->



<!-- <img src="/images/lisa1.png" alt="LISA2"> -->

<!-- ![Lisa](/hayrulablog.github.io/images/lisa1.png) -->
<img src="/hayrulablog.github.io/images/lisa1.png" alt="LISA Overview" align="center" width="600"/> 

**The Skill Predictor:** In the first step the instruction in natural language is analyzed and the preditor identifies the subtask needed to complete the task described. Here the language instruction is split into two independent sub-tasks "pull the handle" and "move black mug right". This is done by predicting quantized skill codes $$z$$ using a learnable codebook $$C$$ which encodes different sub-tasks.  

**The Policy Network:** The skill predictor passes the encoded sub-tasks to the policy network. Based on these the policy predicts what actions the machine should take at each time step and the encoded skill at that time step. The policy also considers the current state of the environment as well as the skill code to make decisions about the next action. 

## Imitation Learning
By far Imitation Learning was mentioned multiple 
## A Deeper Look into the Hierarchy
### Defining the Problem Setup